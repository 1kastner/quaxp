{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Information\n",
    "__Section__: More complex transformations of text  \n",
    "__Goal__: Learn and understand the complex methods of text preprocessing such as stemming, negation handling, stopwords, ...  \n",
    "__Time needed__: x min  \n",
    "__Prerequisites__: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex transformations of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negations and contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words such as \"can't\", \"don't\", in other words, words containing a negative contracted form, could be recognized by our algorithm, however, it is possible to make it simpler by removing the contracted form from the text. A \"not\" is easier to interpret as it is a more frequent word than all the contracted forms.\n",
    "\n",
    "TODO: something like the more a word is recurrent the better information it contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of words are present for syntaxic purposes, but do not add any information for the task if we consider their meaning. Those words, such as \"a\", \"the\", \"for\", etc... should be removed for a more efficient analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: code and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emojis can be a great source of information for sentiment analysis, and it would be a shame to simply discard them. Instead, we can use a mapping function, which gives a corresponding text translation for each emoji. With this example, the emoji \":-)\" will be translated into \"smiling face\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: move this part to the previous page because we already discarded special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Stemming is a linguistic operation consisting of reducing the words to their stem, or root.\n",
    "+ Lemmatisation is a similar operation which groups all words with the same root into one entity.\n",
    "\n",
    "They often give the same result, but not always.\n",
    "\n",
    "For example:\n",
    "\n",
    "| Words | Stemming | Lemmatization |\n",
    "|:-----|:---------|:--------------|\n",
    "| written | writ | write |\n",
    "| writing | writ | write |\n",
    "| gives | giv | give |\n",
    "| finally | final | final |\n",
    "| expected | expect | expect |\n",
    "| picky | pick | pick |\n",
    "\n",
    "This has the impact to consider all the words with the same root as synonyms, as they will be treated as a single word. This makes sense for an algorithm that is trying to detect the general idea of the text more than studying each word one by one. This operation is useful to reduce the number of different words in the data and therefore build a stronger model.\n",
    "\n",
    "A stemming algorithm is easier to write, as the word is only cut and no dictionnary or lookup table is needed, but it can sometimes give uncertain results: for example, the word ``given`` will be reduced to ``giv``, but the word ``gave`` will stay ``gav`` even though those two words have the same root and should be grouped together.  \n",
    "A lemmatization algorithm requires more preleminary resources but gives better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Kumar, Harish, 2018, Classification of Short Text Using Various Preprocessing Techniques: An Empirical Evaluation, Recent Findings in Intelligent Computing Techniques, pp. 19-30.\n",
    "- Arpita et al., 2020, Data Cleaning of Raw Tweets for Sentiment Analysis, 2020 Indo â€“ Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN)\n",
    "- Bitext.com, 2018, [What is the difference between stemming and lemmatization?](https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/), online, accessed 04.12.2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
